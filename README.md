<h1>TDI DATA ENGINEERING PROJECTS - Jude Raji</h1>
<p>I created this repository to kick off my journey into Data Engineering via excellent coaching from TDI (The Data Immersed) Community.</p>
<p>The first Project (titanic_analysis.ipynb) contains the Analysis of the titanic dataset from <a href="https://www.kaggle.com/datasets/brendan45774/test-file">Kaggle</a></p>
<p>WK1: Tasks included:</p>
<li> Importing the csv file into the notebook.</li>
<li> Checking for and handling missing values.</li>
<li> Checking for and handling duplicates.</li>
<li> Exploratory data analysis.</li>
<li> Data Visualization (bar charts)</li>
<P> </P>
<P>WK2: Tasks included:</P>
<l1> Creating a Class for Titanic Data Cleaner.</l1>
<li> Adding methods for loading data, filling in missing values, removing duplicates, and applying transformations.</li>
<li> Adding Transformation functions to this class, and wiring methods for binning age into cateories, and creating family column</li>
<li> Adding a method to map the embarked column to their correct names</li>
<li> Then using 'argparse' to create Command-Line Interface (CLI) - we were given options of argparse and click</li>
<li> Adding logging for steps to the script and setting it to output to an INFO file.</li>
<p> </p>
<p>WK3: Taks included:</p>
<li> Fetching data from a site using API</li>
<li> Saving this data to a parquet file</li>
<li> Saving this data to an excel (xlsx) file</li>
<li> Setting up and scheduling periodic updates</li>
